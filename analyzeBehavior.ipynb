{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3fc5928-1fa0-4907-b619-437026c9e140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from utils import import_data, get_accuracy, get_accuracy_by_cue, plot_accuracy, plot_accuracy_by_cue, save_fig\n",
    "from supplemental_data import rule_change, cscheme, cue_names, reward_arms\n",
    "\n",
    "import datetime\n",
    "timestamp = datetime.datetime.today().strftime(\"%Y-%m-%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8de3914-06df-4a07-9908-c34f9aceb680",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import data\n",
    "Specify the list of all animals and the directory the csv files are. Choose a subset of animals to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c1edd80-3bc6-4c22-a84c-f2fbb2f0b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(datadir, animal):\n",
    "    \"\"\"\n",
    "    Takes the data directory and animal name in format JC2xx as an input, and imports the data \n",
    "    from a csv file into a dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    datadir : the directory that contains the csv files for each animal.\n",
    "    animal : a string with the animal name in JC2xx format.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : a dictionary of dataframes with data for each animal.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    path = datadir+animal+'_data.csv'\n",
    "    data = pd.read_csv(path)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f46fb49-f032-4215-90a3-16e36ca29ec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_animals = [\n",
    "    'JC240',\n",
    "    'JC241',\n",
    "    'JC258',\n",
    "    'JC267',\n",
    "    'JC274',\n",
    "    'JC283',\n",
    "]\n",
    "\n",
    "datadir = 'data/'\n",
    "\n",
    "animals = all_animals[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f20e49-f09b-4a6a-a324-5caf7754c514",
   "metadata": {},
   "source": [
    "Import animal data and store them in a dict under animal name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "550d674f-8d63-4e37-a971-727e1a478479",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "for animal in animals:\n",
    "    data[animal] = import_data(datadir,\n",
    "                               animal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131159ee-bfcb-4e98-94e6-1d835fb424e4",
   "metadata": {},
   "source": [
    "Get the number of training days for each animal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed937755-c456-4965-8383-df33483d1b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sessions = {}\n",
    "\n",
    "for animal in animals:\n",
    "    sessions[animal] = data[animal]['Session_ID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d00b8fe-4516-44aa-8be5-c93af2284433",
   "metadata": {},
   "source": [
    "Calculate the accuracy for each training day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a70d6846-a103-4f92-a486-cc270c6cacdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = {}\n",
    "\n",
    "for animal in animals:\n",
    "    accuracy[animal] = get_accuracy(data,\n",
    "                                    animal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32be4e92-74c9-4a2c-a937-097ca007f5c8",
   "metadata": {},
   "source": [
    "Get the unique food cues for each experiment. Calculate the accuracy by training day and food cue type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dbd31f2-11fa-40e9-990b-3ac9e2ac6eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cues = {}\n",
    "accuracy_by_cue = {}\n",
    "\n",
    "for animal in animals:\n",
    "    cues[animal] = data[animal]['Flavor'].unique()\n",
    "    accuracy_by_cue[animal] = get_accuracy_by_cue(data,\n",
    "                                                  animal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ad5df-20d2-4b0d-888c-248a8315def9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Pandas tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e2f92d6-6cde-464f-bce3-350951ff20fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# list arm counts by session (one row for each arm within each session)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m arm_counts \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSession_ID\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArm\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# list arm counts by session (one row for each arm within each session)\n",
    "arm_counts = df[['Session_ID','Arm']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1956e8ae-a3dd-40a0-af85-be3ef72d9adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all entries for session 1\n",
    "sess1 = df[df['Session_ID'] == 1]\n",
    "\n",
    "# arm counts for session 1\n",
    "arm_counts_sess1 = sess1['Arm']\n",
    "\n",
    "# all entries for session 1 and arm 1\n",
    "sess1_arm1 = df[(df['Session_ID'] == 1) & (df['Arm']==1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd80be45-2167-4814-bf1b-2f027067d647",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Plot performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f20d89b-30f9-4fd0-a323-fc2a812dfd2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Plot accuracy for all animals\n",
    "Toggle between 2-cue or 3-cue (before and after the rule change)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f93658-e666-4a82-a496-6b402e3caf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndays2cue = max(rule_change.values())-1 # x-val is the maximum value of the rule change day minus one day\n",
    "ndays3cue = np.max(np.concatenate(list(sessions.values()))) # plot max value for all sessions and all animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406d57f5-f633-4e9e-9f9c-9c0c09fcd13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(22,11))\n",
    "\n",
    "for animal in animals:\n",
    "    \n",
    "    ############# TOGGLE VARIABLES #################\n",
    "    # # 2 cues\n",
    "    # acc = accuracy[animal].iloc[:rule_change[animal]-1] # accuracy before rule change\n",
    "    # title='Performance before rule change'\n",
    "    # ndays=ndays2cue\n",
    "    \n",
    "    # 3 cues\n",
    "    acc = accuracy[animal].iloc[:rule_change[animal]] # accuracy after rule change\n",
    "    title='Performance after rule change'\n",
    "    ndays=ndays3cue\n",
    "    \n",
    "    ################################################\n",
    "    \n",
    "    \n",
    "    plot_accuracy(\n",
    "        acc,\n",
    "        animal,\n",
    "        ndays=ndays,\n",
    "        title=title,\n",
    "        fig=fig,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# save_fig('Performance 2cues', 'svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338ebace-d4f2-4b97-99e9-0d648e379627",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot performance by cue type (all animals)\n",
    "Toggle between 2-cue or 3-cue (before and after the rule change)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32199d13-4f90-4506-aebe-faf98d9db4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a large plot with 4 subplots\n",
    "rows, cols = 2, 2\n",
    "fig, axes = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(22,15))\n",
    "title='Performance by cue type'\n",
    "fig.suptitle(title, fontsize=50, y=1.03)\n",
    "\n",
    "# Iterate over each subplot and plot.\n",
    "for ax, animal in zip(axes.flatten(), animals):\n",
    "    \n",
    "    ############# TOGGLE VARIABLES #################\n",
    "    # # 2 cue\n",
    "    # data_by_cue = accuracy_by_cue[animal].loc[:rule_change[animal]-1]\n",
    "    # ndays=ndays2cue\n",
    "    # cues_select=cues[animal][:2]\n",
    "    # rule_ch_line=False\n",
    "    \n",
    "    # 3 cue\n",
    "    data_by_cue = accuracy_by_cue[animal]\n",
    "    ndays=ndays3cue\n",
    "    cues_select=cues[animal]\n",
    "    rule_ch_line=True\n",
    "    ###############################################\n",
    "    \n",
    "    plot_accuracy_by_cue(\n",
    "        data_by_cue=data_by_cue,\n",
    "        animal=animal,\n",
    "        cues=cues_select,\n",
    "        ndays=ndays,\n",
    "        background=cscheme[animal+'_medium'],\n",
    "        fig=fig,\n",
    "        ax=ax,\n",
    "        rule_ch_line=rule_ch_line,\n",
    "    )\n",
    "    \n",
    "    # Plot legend on JC267 subplot\n",
    "    if animal == 'JC267':\n",
    "        legend_handles = []\n",
    "        for cue, color in cue_names.items():\n",
    "            legend_handles.append(plt.Line2D([],[], color=color, label=cue, linewidth=3, marker='o', markersize=8))\n",
    "        ax.legend(handles=legend_handles, loc=7, fontsize=30, framealpha=1)\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "# save_fig('Performance all animals light tint', 'svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108a6428-72c4-4b91-82a2-3c1c9e07490e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot performance by cue type (individual animal)\n",
    "Toggle between 2-cue or 3-cue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01276ff9-9646-40d3-8c3a-a7c463d47a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal='JC258'\n",
    "\n",
    "############# TOGGLE VARIABLES #################\n",
    "# 2 cues\n",
    "data_by_cue = accuracy_by_cue[animal].loc[:rule_change[animal]-1] # accuracy before rule change\n",
    "ndays=ndays2cue # or rule_change[animal]-1\n",
    "cues_select=cues[animal][:2]\n",
    "\n",
    "# # 3 cues\n",
    "# data_by_cue = accuracy_by_cue[animal]\n",
    "# ndays=ndays3cue # or len(sessions[animal])\n",
    "# cues_select=cues[animal]\n",
    "################################################\n",
    "\n",
    "plot_accuracy_by_cue(\n",
    "    data_by_cue=data_by_cue,\n",
    "    animal=animal,\n",
    "    cues=cues_select,\n",
    "    ndays=ndays,\n",
    "    background=cscheme[animal+'_medium']\n",
    "                    )\n",
    "\n",
    "# save_fig(f'Performance {animal}', 'svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eab4f53-84e1-466d-92b9-756ed921353a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Plot failed schema learning with JC240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1041fd83-cbfa-4efb-ad1c-3e1a2e7a9519",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = 'JC240'\n",
    "data_JC240 = {}\n",
    "data_JC240[animal] = import_data(datadir, animal)\n",
    "accuracy_JC240 = get_accuracy(data_JC240, animal)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(22,11))\n",
    "\n",
    "plot_accuracy(accuracy_JC240, animal, title=\"JC240: failed schema learning\", fig=fig, ax=ax, legend=False)\n",
    "ax.axvline(x = rule_change[animal], c='k')\n",
    "ax.text(rule_change[animal], 80, \"rule change\", rotation=90, fontsize=16)\n",
    "\n",
    "plt.show()\n",
    "# save_fig('JC240 failed schema learning', 'svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a48a08e-f2af-4dce-96d5-559d8ee9aee3",
   "metadata": {},
   "source": [
    "# Plot arm selection over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d3be38-6d61-4a2d-aa25-d5ffcc1669ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(data, animal):\n",
    "    \"\"\"\n",
    "    Returns an array of trial accuracy (% trials correct) by training day.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : a dictionary of dataframes with data for each animal.\n",
    "    animal : a string with the animal name in JC2xx format.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    accuracy : returns a dictionary of series with accuracy for each animals.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # group data by training days\n",
    "    df = data[animal] # call the dataframe for that animal\n",
    "    df_grouped = df.groupby('Session_ID')\n",
    "    \n",
    "    # for each day, divide the correct trials over the total trials\n",
    "    correct = df_grouped['CorrectBool'].sum() # count correct trials in each day\n",
    "    total = df_grouped['CorrectBool'].count() # count total trials in each day\n",
    "    accuracy = np.round(correct/total*100, 2)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e30eab-7bde-41c3-9261-5a2c28d97b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Calculate arm choice by session #####\n",
    "def get_arm_choice(JCxxx, rewardArms):\n",
    "    # data_JCxxx = str(JCxxx) + \"_data\" # concatenate strings for variable name\n",
    "    df = data[animal]\n",
    "    # data_JCxxx = globals()[data_JCxxx] # convert string to variable\n",
    "    # bysession_JCxxx = data_JCxxx.groupby(\"Session_ID\") # filter by session ID and create a groupby object\n",
    "    df_grouped = data[animal].groupby('Session_ID')\n",
    "    # sessions = bysession_JCxxx[\"Session_ID\"].unique() # list sessions\n",
    "    arms = rewardArms # list arms of interest\n",
    "    num_arms = len(arms) # count arms\n",
    "    arm_choice = np.zeros((len(sessions), num_arms+1)) # make a vector that will hold arm choice for each session\n",
    "                                                        # and add another column for other arms\n",
    "    num_trials = np.zeros(len(sessions))\n",
    "    for session in range(1, len(sessions)+1): # iterate over sessions, starting at 1 instead of 0\n",
    "        num_trials[session-1] = bysession_JCxxx.get_group(session).count()[0] # count number of trials per session\n",
    "        for arm in range(num_arms): # iterate over arms by indexing numpy array\n",
    "            this_session = bysession_JCxxx.get_group(session)\n",
    "            choices_bool = this_session[\"Arm\"]==(arms[arm]) # Boolean of whether arm was chosen\n",
    "            count = len(choices_bool[choices_bool==True])\n",
    "            arm_choice[session-1][arm] = count\n",
    "        arm_choice[session-1][-1] = num_trials[session-1] - arm_choice[session-1][0] - arm_choice[session-1][1] - arm_choice[session-1][2]\n",
    "                                    # for last column subtract arms of interest from total trials\n",
    "    arm_choice = arm_choice / num_trials[:,None] # express arm choice as a proportion of total trials\n",
    "    return num_trials, arm_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "05328d8c-90d6-4d48-9c36-4e990782f165",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = 'JC283'\n",
    "\n",
    "df = data[animal]\n",
    "df_grouped = df.groupby('Session_ID')\n",
    "arms = df['Arm'].unique()\n",
    "reward_arms[animal]\n",
    "num_trials = df_grouped.size()\n",
    "arm_counts = df_grouped['Arm'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "af922b64-d62d-4c9e-b25e-a4c34ebb0b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Session_ID  Arm\n",
       "1           3      10\n",
       "            8       9\n",
       "            1       4\n",
       "            4       4\n",
       "            2       1\n",
       "                   ..\n",
       "14          5      37\n",
       "            8      32\n",
       "            4       4\n",
       "            1       1\n",
       "            3       1\n",
       "Name: Arm, Length: 67, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arm_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9878b17d-3ac6-45cd-b439-d408d2fc5587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Arm\n",
       "5    0.493333\n",
       "8    0.426667\n",
       "4    0.053333\n",
       "1    0.013333\n",
       "3    0.013333\n",
       "Name: Arm, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arm_counts_proportion = {}\n",
    "\n",
    "# for session in sessions[animal]:\n",
    "#     arm_counts_proportion[session] = arm_counts[session] / num_trials[session]\n",
    "\n",
    "arm_counts_proportion = arm_counts[session] / num_trials[session]\n",
    "arm_counts_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "42160ac0-e669-475a-bd14-5c7e1cf497fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43marm_counts_proportion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m'\u001b[39m, stacked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'plot'"
     ]
    }
   ],
   "source": [
    "arm_counts_proportion.plot(kind='bar', stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a0b5f5-7158-43e3-a59c-bf959441c5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a761d4-068c-4453-ac55-f667e5dbe066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "160dc185-9188-46b1-93b5-566a8ac0cc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "arm_counts = {}\n",
    "\n",
    "for animal in animals:\n",
    "    arm_counts[animal] = data[animal].groupby('Session_ID')['Arm'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68be442f-ecf9-42c1-a926-372d5a5d8f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Session_ID  Arm\n",
       "1           3      10\n",
       "            8       9\n",
       "            1       4\n",
       "            4       4\n",
       "            2       1\n",
       "                   ..\n",
       "14          5      37\n",
       "            8      32\n",
       "            4       4\n",
       "            1       1\n",
       "            3       1\n",
       "Name: Arm, Length: 67, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arm_counts[animal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7923306-21b8-4d03-ac2a-70bc3415920a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animal='JC283'\n",
    "session = 1\n",
    "arm = 8\n",
    "\n",
    "arm_counts[animal][session][arm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af73381-c288-4ef3-856e-714bd1bbb6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c637936-4414-4dd4-ac29-55d5f1017d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3354282b-7940-4f9b-acdc-4209c8c0c33c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
